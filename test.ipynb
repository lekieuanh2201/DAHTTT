{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from elasticsearch import Elasticsearch\n",
    "import os\n",
    "from unidecode import unidecode\n",
    "import string\n",
    "import re\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "es = Elasticsearch(\"http://localhost:9200\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql.types import StringType\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"YourAppName\") \\\n",
    "    .config(\"spark.driver.memory\", \"2g\") \\\n",
    "    .config(\"spark.executor.memory\", \"2g\") \\\n",
    "    .getOrCreate()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained('vietdata/vietnamese-content-cls')\n",
    "tokenizer = AutoTokenizer.from_pretrained('vietdata/vietnamese-content-cls')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_class(sentence, model, tokenizer):\n",
    "    clas = ['Agriculture, food, and drink',\n",
    " 'Albums',\n",
    " 'Architecture',\n",
    " 'Art',\n",
    " 'Biology and medicine',\n",
    " 'Chemistry and materials science',\n",
    " 'Classical compositions',\n",
    " 'Computing and engineering',\n",
    " 'Earth science',\n",
    " 'Film',\n",
    " 'Geography',\n",
    " 'Language and literature',\n",
    " 'Mathematics and mathematicians',\n",
    " 'Media and drama',\n",
    " 'Other music articles',\n",
    " 'Philosophy',\n",
    " 'Physics and astronomy',\n",
    " 'Places',\n",
    " 'Religion',\n",
    " 'Royalty, nobility, and heraldry',\n",
    " 'Songs',\n",
    " 'Television',\n",
    " 'Transport',\n",
    " 'World history',\n",
    " 'Armies and military units',\n",
    " 'Baseball',\n",
    " 'Basketball',\n",
    " 'Battles, exercises, and conflicts',\n",
    " 'Culture, sociology, and psychology',\n",
    " 'Economics and business',\n",
    " 'Education',\n",
    " 'Football',\n",
    " 'Hockey',\n",
    " 'Law',\n",
    " 'Magazines and print journalism',\n",
    " 'Military aircraft',\n",
    " 'Military decorations and memorials',\n",
    " 'Military people',\n",
    " 'Motorsport',\n",
    " 'Multi-sport event',\n",
    " 'Other sports',\n",
    " 'Politics and government',\n",
    " 'Pro wrestling',\n",
    " 'Recreation',\n",
    " 'Video games',\n",
    " 'Warships and naval units',\n",
    " 'Weapons, equipment, and buildings']\n",
    "    input_ids = torch.tensor([tokenizer.encode(sentence)])\n",
    "    with torch.no_grad():\n",
    "            out = model(input_ids)\n",
    "            probs = out.logits.softmax(dim=-1).tolist()[0]\n",
    "            top_2_indices = np.argsort(probs)[-2:]\n",
    "    return clas[top_2_indices[0]], clas[top_2_indices[1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_class(\"Thủ tướng đi ngoại giao\", model, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(txt):\n",
    "    # Code here\n",
    "    ###########\n",
    "    return predict_class(txt, model, tokenizer)\n",
    "\n",
    "def normalize_index(txt: str)->str:\n",
    "    translator = str.maketrans('', '', string.punctuation)\n",
    "    # Use the translate method to remove punctuation\n",
    "    rs = txt.translate(translator)\n",
    "    rs = unidecode(rs).strip()\n",
    "    rs = rs.replace(' ', '_')\n",
    "    return rs.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = './data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = None\n",
    "for file in os.listdir(data_dir):\n",
    "    f_path = os.path.join(data_dir, file)\n",
    "    if df == None:\n",
    "        df = spark.read.option(\"encoding\", \"utf-8\").json(f_path)\n",
    "    else:\n",
    "        new_df = spark.read.option(\"encoding\", \"utf-8\").json(f_path)\n",
    "        df = df.union(new_df)\n",
    "\n",
    "# df.show()\n",
    "rdd = df.rdd\n",
    "\n",
    "# processed_rdd = rdd.map(preprocess)\n",
    "\n",
    "# processed_rdd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdd.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_list = es.cat.indices(format=\"json\")\n",
    "\n",
    "# Xóa từng index trong danh sách\n",
    "for index in index_list:\n",
    "    index_name = index['index']\n",
    "    es.indices.delete(index=index_name)\n",
    "\n",
    "print(\"All indices have been deleted.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in rdd.collect():\n",
    "  try:\n",
    "    cate1, cate0 = predict_class(x['text'], model, tokenizer)\n",
    "    data = {   \n",
    "            'page': x['page'],\n",
    "            'post_id': x['post_id'],\n",
    "            'text': x['text'],\n",
    "            'timestamp': x['timestamp'],\n",
    "            'likes': int(x['likes']),\n",
    "            'comments': int(x['comments']),\n",
    "          }\n",
    "    print(cate1, cate0)\n",
    "    es.index(index=normalize_index(cate1), document=data)\n",
    "    es.index(index=normalize_index(cate0), document=data)\n",
    "\n",
    "  except:\n",
    "    continue"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "crawler",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
